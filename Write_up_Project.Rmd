---
title: "Project_writup"
author: "Shuai Wang"
date: "July 20, 2014"
output: html_document
---
Dear peers and graders,
Thanks for grading this write_up project! I will describe what I have been doing follwed by the project instruction as well as important procedures learned from class materials. Any of your advice and feedback are valueable for our better understanding of the class lectures.

## 1 The goal of this project

As desribed in the descrption, the goal of this piece of data is to "predict in which they did the exercise". ". More specially, the "classe" variable that contains "ABCDE" five categories are dependent variable. 

As we learned from week 1, the first thing I did is to look at what the training data looks like. The nature of the data several volunteers's data on many variables. The snapshot of some variables(you know it is very long!) is shown below:
```{r}

```

### 1.1 In and out of sample errors

So by observations, I notice that there are *six* people's data. Since the goal of to predict in which *they* did the excercise, so it is important to conside this factor *before* we train our model. To reduce in-sample errors, we can subset the raw dataset into six dataset with certain names. In other words, we *taliored* the raw data for target people. Actually it greatly reduced out of sample errors in variability of person. Other out of sample errors such as the test case is much smaller so we need to control the virance in order to make the predict model work. Key code is shown below for one example user:

    *select_subset<- function(DF,DF_test,sub_name)*

*(DF is traing data frame with sub_name, DF_test is test data frame with sub_name, the predict model will be tailored based on the person)*

details will be given in cleaning procedure since it has to be done in both training and test data set in the same way.


### 1.2 Data cleaning

another observation from raw data is there are many variables have missing value or nonsense value.
[snap shot of raw data]
(https://github.com/ShuaiGitHub/Rmd_markdown_project/blob/master/capture.png)

    *nzv <- nearZeroVar(training_sub); find variables that have near zero variance*
  
    *New_sub <- training_sub[,-nzv]; delete them in training set*
  
    *New_testSub <-test_sub[,-nzv]; delete same columns in test set*
After cleaning, the data summary of one subject was shown below (so many are deleted!):
  
  
## 2 Building models

### 2.1 cross validation, metric, and model selection
Then the data is sliced by creataDataPartitation in two parts:training and testing for cross validation. Default cross validation such as resampling 25times were also used in train() function.

### 2.1.1 Machine Learning Algrothim: GLM
Actually the first model I try is general linear model since it was learned in week 1(...). The basic idea is simple: after center and scale all remaining variables, fit train(...,method="glm"), when classes is considered as numeric variable.Since the classe is still integer number, So fitted results are rounded to nearest integer by round(). RMSE is used as metric.The result for "adelmo" is shown below(using subject "adelmo"" as an example):

### 2.1.2 Machine Learning Algrothim:Rpart decision tree
The "perfect" 0 value for RMSE indicate there might be overfitting and something weird. When I apply it to real test, I got large nonsense numbers(-588333 etc) for test data's classe. So it seems that non-linear models are better options. Since the outcome is factor variable, a random forest decision tree was built to predict performance:

    *modelFit <-train(Subject_train$classe ~.,method="rpart",data=trainPC)*

Results for one person is shown below:

So I realize there are some factors disturb the whole tree such as "X","row_names". After I remove those variables, The rpart tree outputs very reasonable results. My first attempt for the project got 85% correct:

    key code: *New_sub <- New_sub[,!(colnames(New_sub) %in% c("cvtd_timestamp","X","row.names"))]* remove unwanted columns

### 2.1.3 Machine learning Algrothim: Random Forest

Since we already know decision tree(rpart) can provide 85% correct. So it is easier for us to try other non-linear algrothim on the test data that got wrong(Jeremy's model). The train function for random forest is shown below:

    *modelFit <-train(Subject_train$classe ~.,number=3,method="rf",trControl=trainControl("cv"),data=trainPC)*

This time I got the rest 3 correct.

Thanks for reading it!

Best,

Shuai

